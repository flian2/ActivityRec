{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from clean_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for person 4. Use sequence 1~3 for training, 4~5 for testing.\n",
    "person = 4\n",
    "sadl_n = []\n",
    "for n in range(1, 6):\n",
    "    sadl_n.append(pd.read_table('data/S%d-ADL%d.dat' % (person, n), sep='\\s+', header=None, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample size:  (11806, 36)\n",
      "train_labels size:  (11806,)\n",
      "subsequence length:  [5198 3467 3141] . Sum of length:  11806\n",
      "test_sample size:  (6593, 36)\n",
      "test_labels size:  (6593,)\n",
      "subsequence length:  [2778 3815] . Sum of length:  6593\n"
     ]
    }
   ],
   "source": [
    "# Smooth data, time: col 0, features: col 1~36, labels: col 244 \n",
    "winsize = 15\n",
    "stepsize = 8\n",
    "\n",
    "# train data\n",
    "train_sample = np.empty((0, 36))\n",
    "train_labels = np.empty((0))\n",
    "train_len = []\n",
    "for i in range(0, 3):\n",
    "    features = moving_avg(sadl_n[i].iloc[:, 1:37], winsize, stepsize)\n",
    "    labels = moving_vote_majority(sadl_n[i].iloc[:, 244], winsize, stepsize)\n",
    "    train_sample = np.concatenate((train_sample, features), axis=0)\n",
    "    train_len.append(features.shape[0])\n",
    "    train_labels = np.concatenate( (train_labels, labels) )\n",
    "train_len = np.array(train_len)\n",
    "\n",
    "print \"train_sample size: \", train_sample.shape\n",
    "print \"train_labels size: \", train_labels.shape\n",
    "print \"subsequence length: \", train_len, \". Sum of length: \", np.sum(train_len)\n",
    "\n",
    "# test data\n",
    "test_sample = np.empty((0, 36))\n",
    "test_labels = np.empty((0))\n",
    "test_len = []\n",
    "for i in range(3, 5):\n",
    "    features = moving_avg(sadl_n[i].iloc[:, 1:37], winsize, stepsize)\n",
    "    labels = moving_vote_majority(sadl_n[i].iloc[:, 244], winsize, stepsize)\n",
    "    test_sample = np.concatenate((test_sample, features), axis=0)\n",
    "    test_len.append(features.shape[0])\n",
    "    test_labels = np.concatenate( (test_labels, labels) )\n",
    "test_len = np.array(test_len)  \n",
    "\n",
    "print \"test_sample size: \", test_sample.shape\n",
    "print \"test_labels size: \", test_labels.shape\n",
    "print \"subsequence length: \", test_len, \". Sum of length: \", np.sum(test_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values\n",
    "col_threshold = 0.5\n",
    "train, test = fill_missing(train_sample, test_sample, col_threshold, True)\n",
    "np.any(np.isnan(train)), np.any(np.isnan(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler() # center to mean and normalize to unit variance\n",
    "train_normalized = scalar.fit_transform(train)\n",
    "test_normalized = scalar.transform(test)\n",
    "train_reduced = train_normalized\n",
    "test_reduced = test_normalized\n",
    "# Cleaned data: train_reduced, test_reduced, train_labels, test_labels, train_len, test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep 22 compoments to retrain 0.950000 variance\n",
      "Size of reduced dimension training data:  (11806, 22)\n",
      "Size of reduced dimension testing data:  (6593, 22)\n"
     ]
    }
   ],
   "source": [
    "# Dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(train_normalized)\n",
    "var_thres = 0.95 # keep components to up to 95% total variance\n",
    "n_comp = (pca.explained_variance_ratio_.cumsum() < var_thres).sum() + 1\n",
    "print \"Keep %d compoments to retrain %f variance\" % (n_comp, var_thres)\n",
    "\n",
    "pca_train = PCA(n_components=n_comp)\n",
    "train_reduced = pca_train.fit_transform(train_normalized)\n",
    "test_reduced = pca_train.transform(test_normalized)\n",
    "print \"Size of reduced dimension training data: \", train_reduced.shape\n",
    "print \"Size of reduced dimension testing data: \", test_reduced.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize upper level left-right hmm model with 6 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability mass P(label | state): \n",
      "[[ 0.82215481  0.17784519  0.          0.          0.          0.        ]\n",
      " [ 0.01197513  0.          0.          0.98802487  0.          0.        ]\n",
      " [ 0.05644644  0.          0.94355356  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.99999999]\n",
      " [ 0.03358826  0.          0.          0.          0.96641174  0.        ]\n",
      " [ 0.7703183   0.2296817   0.          0.          0.          0.        ]]\n",
      "The maximum likelihood label for each state: \n",
      "[0 3 2 5 4 0]\n"
     ]
    }
   ],
   "source": [
    "from hmm import DiscreteDistr, GaussDistr, GaussMixDistr\n",
    "from hmm import MarkovChain\n",
    "from hmm import HMM, make_leftright_hmm\n",
    "\n",
    "# Build a left-right hmm with 6 states, discrete output distribution, the output is the discrete label of activity\n",
    "label_transfer = (np.maximum(train_labels - 100, 0) + 1)[:, np.newaxis]\n",
    "# transform the labels into range 1~6. {0: 1, 101: 2, 102: 3, 103: 4, 104: 5, 105: 6}\n",
    "discreteD = DiscreteDistr(np.ones((6))) # a discrete distribution with 6 possible output\n",
    "n_states = 6\n",
    "\n",
    "hmm_state = make_leftright_hmm(n_states, discreteD, obs_data=label_transfer, l_data=train_len)\n",
    "print \"Probability mass P(label | state): \"\n",
    "prob_mass = np.zeros((n_states, n_states))\n",
    "for i in range(0, n_states):\n",
    "    prob_mass[i, :] = hmm_state.output_distr[i].prob_mass\n",
    "prob_mass[prob_mass < 1e-2] = 0\n",
    "print prob_mass\n",
    "\n",
    "# Assign max probability activity label to each state\n",
    "# If multiple states are assigned with one same label, then inside each of these states use a small hmm \n",
    "state_act_label = np.array([np.argmax(prob_mass[i, :]) for i in range(0, n_states)])\n",
    "act_label_count = np.zeros((n_states)) # how many states correspond to label i\n",
    "for i in range(0, n_states):\n",
    "    act_label_count[i] = np.sum(state_act_label == i)\n",
    "print \"The maximum likelihood label for each state: \"\n",
    "print state_act_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mixture</th>\n",
       "      <th>mean_loglikelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-13.13086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.14747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>-25.44256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>-19.12053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>-30.29275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8</td>\n",
       "      <td>-23.86655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_mixture mean_loglikelihood\n",
       "0           9          -13.13086\n",
       "101         1          -37.14747\n",
       "102         2          -25.44256\n",
       "103         2          -19.12053\n",
       "104         2          -30.29275\n",
       "105         8          -23.86655"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train output distribution\n",
    "def search_num_mixtures_likelihood(features, train_len, n_mix):\n",
    "    # Use cross validation on loglikehood to find the optimal number of mixtures for each class label\n",
    "    # return: \n",
    "    # gmm: the gmm model that gives the highest mean logprob\n",
    "    # N: number of gaussian mixtures in the gmm\n",
    "    # logp_x: mean of logP(Xt | gmm) for the chosen gmm\n",
    "    mean_logprob = [0 for i in range(0, len(n_mix))] # mean of logP(Xt | gmm)\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    for i, N in enumerate(n_mix):\n",
    "        # K-fold cross validataion, each fold is one subsequence\n",
    "        n_folds = len(train_len)\n",
    "        likelihood_scores = []\n",
    "        for k in range(0, n_folds):\n",
    "            val_mask = np.zeros((features.shape[0])).astype(bool)\n",
    "            val_mask[start_ind[k]: start_ind[k] + train_len[k]] = True\n",
    "            train_mask = np.logical_not(val_mask)\n",
    "            gmm = GaussMixDistr(gauss=N)\n",
    "            gmm.init_by_data(features[train_mask, :])\n",
    "            gmm.train(features[train_mask, :])\n",
    "            logprob_x = gmm.logprob(features[val_mask, :])\n",
    "            likelihood_scores.append(np.mean(logprob_x))    \n",
    "        mean_logprob[i] = np.mean(likelihood_scores)\n",
    "    # Refit gmm using all data with selected number of mixtures\n",
    "    gmm_list = [] # one gmm model for each \"number of components\"\n",
    "    i_gmm = np.argmax(mean_logprob)\n",
    "    n_components = n_mix[i_gmm]\n",
    "    gmm_opt = GaussMixDistr(gauss=n_components)\n",
    "    gmm_opt.init_by_data(features)\n",
    "    gmm_opt.train(features)\n",
    "    likelihood_score = np.mean(gmm_opt.logprob(features))\n",
    "    return gmm_opt, n_components, likelihood_score\n",
    "\n",
    "def make_outputdistr(train, train_len, train_labels, class2label):\n",
    "    outputdistr_stats = pd.DataFrame(index=class2label, columns=['n_mixture', 'mean_loglikelihood'])\n",
    "    outputdistr_gmm = []\n",
    "    n_mix = range(1, 11)\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    for i, label in enumerate(class2label):\n",
    "        per_label_trainlen = [sum(train_labels[start_ind[k]: start_ind[k] + length] == label) for k, length in enumerate(train_len)]\n",
    "        gmm, N, logprob = search_num_mixtures_likelihood(train[train_labels == label], per_label_trainlen, n_mix)\n",
    "        outputdistr_gmm.append(gmm)\n",
    "        outputdistr_stats.iloc[i, :] = [N, logprob]\n",
    "    return outputdistr_gmm, outputdistr_stats\n",
    "\n",
    "class2label = [0, 101, 102, 103, 104, 105]\n",
    "outputdistr_gmm, outputdistr_stats = make_outputdistr(train_reduced, train_len, train_labels, class2label)\n",
    "outputdistr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make new hmm\n",
    "# hmm_gmm = HMM(markov_chain=mc_label, output_distr=outputdistr_gmm_opt)\n",
    "# Compute: P(X(t) | state = i ) for t = 0...T, i = 0...5\n",
    "# P(X(t) | state = i ) = \\sum_{label i} P(X(t) | label = j, state = i) * P(label = j | state = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loglikelihood(mc, x, prob_mass, gmms):\n",
    "    T = x.shape[0]\n",
    "    n_states = mc.n_states\n",
    "    logp_x = np.zeros((n_states, T))\n",
    "    for state in range(0, mc.n_states):\n",
    "        label_ind = np.argwhere(prob_mass[state, :] > 0)\n",
    "        p0 = prob_mass[state, prob_mass[state, :] > 0]\n",
    "        logprob_per_label = gmms[0].logprob(x, [gmms[i] for i in label_ind])\n",
    "        logp_x[state, :] = np.log( p0[np.newaxis, :].dot(np.exp(logprob_per_label)) )[0, :]\n",
    "\n",
    "    return logp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi_state_sequence(mc, x, x_len, prob_mass, gmms):\n",
    "    # x: [T, data_size]. vector sequence stacked together\n",
    "    # x_len: length of subsequences\n",
    "    # Return:\n",
    "    # s_opt: [T, ] predicted state sequence\n",
    "    # logP: [n_seq, ] logP of each subsequence\n",
    "    start_ind = 0\n",
    "    s_opt = np.zeros((x.shape[0]))\n",
    "    logP = np.zeros((len(x_len)))\n",
    "    for i in range(0, len(x_len)):\n",
    "        logp_x = loglikelihood(mc, x[start_ind:start_ind + x_len[i], :], prob_mass, gmms)\n",
    "        s_opt[start_ind: start_ind + x_len[i]], logP[i] = mc.viterbi(logp_x)\n",
    "        start_ind += x_len[i]\n",
    "    return s_opt - 1, logP # the state sequence index from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict label within each state\n",
    "# Make an ergordic hmm with output distribution 1.0, (1-to-1 mapping between label and substate)\n",
    "\n",
    "train_states, _ = viterbi_state_sequence(hmm_state.state_gen, train_reduced, train_len, prob_mass, outputdistr_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sub_hmm(train_states, train_len, train_labels, n_states):\n",
    "    train_labels = train_labels[:, np.newaxis]\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    mc_per_state = []\n",
    "    for n in range(0, n_states):\n",
    "        x_labels = train_labels[train_states == n, :]\n",
    "        x_len = np.array([np.sum(train_states[s:s + train_len[i]] == n) for i, s in enumerate(start_ind)])\n",
    "        x_len = x_len[x_len > 0]\n",
    "        # Aii = 1 - 1/state_duration, Aij = 1/state_duration / (n_states_actual - 1)\n",
    "        A0 = np.eye((n_states))\n",
    "        D = np.array([np.sum(x_labels == i) / float(len(x_len)) for i in range(0, n_states)])\n",
    "        n_states_actual = np.sum(D > 0)\n",
    "        for i in range(0, n_states):\n",
    "            if D[i] == 0:\n",
    "                continue\n",
    "            A0[i, D > 0] = 1.0 / D[i] / n_states_actual\n",
    "            A0[i, i] = 1.0 - 1.0 / D[i]\n",
    "        p0 = np.ones((n_states)) / float(n_states_actual)\n",
    "        p0[D == 0] = 0.0\n",
    "        prob_mass = np.eye((n_states))\n",
    "        pD = [DiscreteDistr(prob_mass[i, :]) for i in range(0, n_states)]\n",
    "        mc = MarkovChain(p0, A0)\n",
    "        hmm_mc = HMM(mc, pD)\n",
    "        hmm_mc.train(obs_data=x_labels + 1, l_data=x_len) # discrete distribution index from 1 \n",
    "        mc_per_state.append(hmm_mc.state_gen)\n",
    "        \n",
    "    return mc_per_state\n",
    "    \n",
    "sub_mcs = make_sub_hmm(train_states, train_len, np.maximum(0, train_labels - 100), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict activity labels inside each high-level hmm state\n",
    "def predict_subhmm_labels(level_one_states, obs_data, l_data, sub_mcs, outputdistr):\n",
    "    # Input:\n",
    "    # level_one_states: [n_samples, ]. Sequences of states of high level hmm.\n",
    "    # obs_data: [n_samples, n_features]\n",
    "    # l_data: length of sequences. sum(l_data) = len(level_one_states)\n",
    "    # sub_mcs: MarkovChain objects for each high-level state. The order of states in the mc corresponds to the low-level label.\n",
    "    # outputdistr: the output distribution for the states in sub_mcs.\n",
    "    # Return:\n",
    "    # labels_opt: [n_samples, ]. predicted labels\n",
    "    start_ind = [0] + list(np.cumsum(l_data)[:-1].astype(int))\n",
    "    labels_opt = np.zeros((level_one_states.shape[0]))\n",
    "    cur_pos = 0\n",
    "    for t in range(0, len(l_data)):\n",
    "        state_subseq = level_one_states[start_ind[t]:start_ind[t] + l_data[t]]\n",
    "        obs_subseq = obs_data[start_ind[t]:start_ind[t] + l_data[t], :]\n",
    "        diff = np.append(np.array([1]), state_subseq[1:] - state_subseq[:-1])\n",
    "        i_newstate = np.append( np.argwhere(diff != 0), np.array([len(diff)]) )\n",
    "        for m in range(0, len(i_newstate) - 1):\n",
    "            state_tt = int(state_subseq[i_newstate[m]])\n",
    "            obs_tt = obs_subseq[i_newstate[m]:i_newstate[m + 1], :]\n",
    "            # run viterbi on markov chain sub_mcs[state_tt]\n",
    "            logp_x = outputdistr[0].logprob(obs_tt, outputdistr)\n",
    "            labels_tt, logP = sub_mcs[state_tt].viterbi(logp_x)\n",
    "            labels_opt[cur_pos:cur_pos + len(labels_tt)] = labels_tt - 1 # make the label index starting from 0\n",
    "            cur_pos += len(labels_tt)\n",
    "    return labels_opt   \n",
    "\n",
    "# Predict test labels\n",
    "test_states, _ = viterbi_state_sequence(hmm_state.state_gen, test_reduced, test_len, prob_mass, outputdistr_gmm)\n",
    "predicted_labels = predict_subhmm_labels(test_states, test_reduced, test_len, sub_mcs, outputdistr_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEZCAYAAACZ7CwhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b04e9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.797057485212\n"
     ]
    }
   ],
   "source": [
    "# Test with ADL4, ADL5\n",
    "true_labels = np.maximum(0, test_labels - 100)\n",
    "\n",
    "plt.plot(predicted_labels, '.', label=\"estimated label\")\n",
    "plt.plot(true_labels, '-', label=\"true label\")\n",
    "plt.plot(test_states, '--', label=\"high-level states\")\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('Activity label')\n",
    "plt.title(\"ADL4, ADL5 -- person %d\" % person)\n",
    "plt.legend(loc=9, bbox_to_anchor=(1.2, 1))\n",
    "plt.show()\n",
    "\n",
    "print \"accuracy: \", sum(predicted_labels == true_labels) / float(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score:  0.808818639618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7268074</td>\n",
       "      <td>0.6847498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8116711</td>\n",
       "      <td>0.9473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4502196</td>\n",
       "      <td>0.8938953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957429</td>\n",
       "      <td>0.9183347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9725664</td>\n",
       "      <td>0.844086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9927007</td>\n",
       "      <td>0.6938776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision     recall\n",
       "0  0.7268074  0.6847498\n",
       "1  0.8116711  0.9473684\n",
       "2  0.4502196  0.8938953\n",
       "3   0.957429  0.9183347\n",
       "4  0.9725664   0.844086\n",
       "5  0.9927007  0.6938776"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print \"Weighted F1 score: \", f1_score(true_labels, predicted_labels, average='weighted') \n",
    "\n",
    "precision, recall , _, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=None, labels=[0, 1, 2, 3, 4, 5])\n",
    "pr_table = pd.DataFrame(index=range(0, 6), columns=['precision', 'recall'])\n",
    "for i in range(0, n_states):\n",
    "    pr_table.iloc[i, :] = [precision[i], recall[i]]\n",
    "pr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
