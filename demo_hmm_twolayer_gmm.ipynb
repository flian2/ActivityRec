{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from clean_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for person 4. Use sequence 1~3 for training, 4~5 for testing.\n",
    "person = 4\n",
    "sadl_n = []\n",
    "for n in range(1, 6):\n",
    "    sadl_n.append(pd.read_table('data/S%d-ADL%d.dat' % (person, n), sep='\\s+', header=None, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample size:  (11806, 36)\n",
      "train_labels size:  (11806,)\n",
      "subsequence length:  [5198 3467 3141] . Sum of length:  11806\n",
      "test_sample size:  (6593, 36)\n",
      "test_labels size:  (6593,)\n",
      "subsequence length:  [2778 3815] . Sum of length:  6593\n"
     ]
    }
   ],
   "source": [
    "# Smooth data, time: col 0, features: col 1~36, labels: col 244 \n",
    "winsize = 15\n",
    "stepsize = 8\n",
    "\n",
    "# train data\n",
    "train_sample = np.empty((0, 36))\n",
    "train_labels = np.empty((0))\n",
    "train_len = []\n",
    "for i in range(0, 3):\n",
    "    features = moving_avg(sadl_n[i].iloc[:, 1:37], winsize, stepsize)\n",
    "    labels = moving_vote_majority(sadl_n[i].iloc[:, 244], winsize, stepsize)\n",
    "    train_sample = np.concatenate((train_sample, features), axis=0)\n",
    "    train_len.append(features.shape[0])\n",
    "    train_labels = np.concatenate( (train_labels, labels) )\n",
    "train_len = np.array(train_len)\n",
    "\n",
    "print \"train_sample size: \", train_sample.shape\n",
    "print \"train_labels size: \", train_labels.shape\n",
    "print \"subsequence length: \", train_len, \". Sum of length: \", np.sum(train_len)\n",
    "\n",
    "# test data\n",
    "test_sample = np.empty((0, 36))\n",
    "test_labels = np.empty((0))\n",
    "test_len = []\n",
    "for i in range(3, 5):\n",
    "    features = moving_avg(sadl_n[i].iloc[:, 1:37], winsize, stepsize)\n",
    "    labels = moving_vote_majority(sadl_n[i].iloc[:, 244], winsize, stepsize)\n",
    "    test_sample = np.concatenate((test_sample, features), axis=0)\n",
    "    test_len.append(features.shape[0])\n",
    "    test_labels = np.concatenate( (test_labels, labels) )\n",
    "test_len = np.array(test_len)  \n",
    "\n",
    "print \"test_sample size: \", test_sample.shape\n",
    "print \"test_labels size: \", test_labels.shape\n",
    "print \"subsequence length: \", test_len, \". Sum of length: \", np.sum(test_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values\n",
    "col_threshold = 0.5\n",
    "train, test = fill_missing(train_sample, test_sample, col_threshold, True)\n",
    "np.any(np.isnan(train)), np.any(np.isnan(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler() # center to mean and normalize to unit variance\n",
    "train_normalized = scalar.fit_transform(train)\n",
    "test_normalized = scalar.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep 22 compoments to retrain 0.950000 variance\n",
      "Size of reduced dimension training data:  (11806, 22)\n",
      "Size of reduced dimension testing data:  (6593, 22)\n"
     ]
    }
   ],
   "source": [
    "# Dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(train_normalized)\n",
    "var_thres = 0.95 # keep components to up to 95% total variance\n",
    "n_comp = (pca.explained_variance_ratio_.cumsum() < var_thres).sum() + 1\n",
    "print \"Keep %d compoments to retrain %f variance\" % (n_comp, var_thres)\n",
    "\n",
    "pca_train = PCA(n_components=n_comp)\n",
    "train_reduced = pca_train.fit_transform(train_normalized)\n",
    "test_reduced = pca_train.transform(test_normalized)\n",
    "print \"Size of reduced dimension training data: \", train_reduced.shape\n",
    "print \"Size of reduced dimension testing data: \", test_reduced.shape\n",
    "# Cleaned data: train_reduced, test_reduced, train_labels, test_labels, train_len, test_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize upper level left-right hmm model with 6 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability mass P(label | state): \n",
      "[[ 0.82215481  0.17784519  0.          0.          0.          0.        ]\n",
      " [ 0.01197513  0.          0.          0.98802487  0.          0.        ]\n",
      " [ 0.05644644  0.          0.94355356  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.99999999]\n",
      " [ 0.03358826  0.          0.          0.          0.96641174  0.        ]\n",
      " [ 0.7703183   0.2296817   0.          0.          0.          0.        ]]\n",
      "The maximum likelihood label for each state: \n",
      "[0 3 2 5 4 0]\n"
     ]
    }
   ],
   "source": [
    "from hmm import DiscreteDistr, GaussDistr, GaussMixDistr\n",
    "from hmm import MarkovChain\n",
    "from hmm import HMM, make_leftright_hmm\n",
    "\n",
    "# Build a left-right hmm with 6 states, discrete output distribution, the output is the discrete label of activity\n",
    "label_transfer = (np.maximum(train_labels - 100, 0) + 1)[:, np.newaxis]\n",
    "# transform the labels into range 1~6. {0: 1, 101: 2, 102: 3, 103: 4, 104: 5, 105: 6}\n",
    "discreteD = DiscreteDistr(np.ones((6))) # a discrete distribution with 6 possible output\n",
    "n_states = 6\n",
    "\n",
    "hmm_state = make_leftright_hmm(n_states, discreteD, obs_data=label_transfer, l_data=train_len)\n",
    "print \"Probability mass P(label | state): \"\n",
    "prob_mass = np.zeros((n_states, n_states))\n",
    "for i in range(0, n_states):\n",
    "    prob_mass[i, :] = hmm_state.output_distr[i].prob_mass\n",
    "prob_mass[prob_mass < 1e-2] = 0\n",
    "for i in range(0, n_states):\n",
    "    hmm_state.output_distr[i].prob_mass = prob_mass[i, :]\n",
    "print prob_mass\n",
    "\n",
    "# Assign max probability activity label to each state\n",
    "# If multiple states are assigned with one same label, then inside each of these states use a small hmm \n",
    "state_act_label = np.array([np.argmax(prob_mass[i, :]) for i in range(0, n_states)])\n",
    "act_label_count = np.zeros((n_states)) # how many states correspond to label i\n",
    "for i in range(0, n_states):\n",
    "    act_label_count[i] = np.sum(state_act_label == i)\n",
    "print \"The maximum likelihood label for each state: \"\n",
    "print state_act_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mixture</th>\n",
       "      <th>mean_loglikelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-13.48975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.14691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>-25.4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>-19.11997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>-30.29331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8</td>\n",
       "      <td>-23.86709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_mixture mean_loglikelihood\n",
       "0           9          -13.48975\n",
       "101         1          -37.14691\n",
       "102         2           -25.4434\n",
       "103         2          -19.11997\n",
       "104         2          -30.29331\n",
       "105         8          -23.86709"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train output distribution\n",
    "def search_num_mixtures_likelihood(features, train_len, n_mix):\n",
    "    # Use cross validation on loglikehood to find the optimal number of mixtures for each class label\n",
    "    # return: \n",
    "    # gmm: the gmm model that gives the highest mean logprob\n",
    "    # N: number of gaussian mixtures in the gmm\n",
    "    # logp_x: mean of logP(Xt | gmm) for the chosen gmm\n",
    "    mean_logprob = [0 for i in range(0, len(n_mix))] # mean of logP(Xt | gmm)\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    for i, N in enumerate(n_mix):\n",
    "        # K-fold cross validataion, each fold is one subsequence\n",
    "        n_folds = len(train_len)\n",
    "        likelihood_scores = []\n",
    "        for k in range(0, n_folds):\n",
    "            val_mask = np.zeros((features.shape[0])).astype(bool)\n",
    "            val_mask[start_ind[k]: start_ind[k] + train_len[k]] = True\n",
    "            train_mask = np.logical_not(val_mask)\n",
    "            gmm = GaussMixDistr(gauss=N)\n",
    "            gmm.init_by_data(features[train_mask, :])\n",
    "            gmm.train(features[train_mask, :])\n",
    "            logprob_x = gmm.logprob(features[val_mask, :])\n",
    "            likelihood_scores.append(np.mean(logprob_x))    \n",
    "        mean_logprob[i] = np.mean(likelihood_scores)\n",
    "    # Refit gmm using all data with selected number of mixtures\n",
    "    gmm_list = [] # one gmm model for each \"number of components\"\n",
    "    i_gmm = np.argmax(mean_logprob)\n",
    "    n_components = n_mix[i_gmm]\n",
    "    gmm_opt = GaussMixDistr(gauss=n_components)\n",
    "    gmm_opt.init_by_data(features)\n",
    "    gmm_opt.train(features)\n",
    "    likelihood_score = np.mean(gmm_opt.logprob(features))\n",
    "    return gmm_opt, n_components, likelihood_score\n",
    "\n",
    "def make_outputdistr(train, train_len, train_labels, class2label):\n",
    "    outputdistr_stats = pd.DataFrame(index=class2label, columns=['n_mixture', 'mean_loglikelihood'])\n",
    "    outputdistr_gmm = []\n",
    "    n_mix = range(1, 11)\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    for i, label in enumerate(class2label):\n",
    "        per_label_trainlen = [sum(train_labels[start_ind[k]: start_ind[k] + length] == label) for k, length in enumerate(train_len)]\n",
    "        gmm, N, logprob = search_num_mixtures_likelihood(train[train_labels == label], per_label_trainlen, n_mix)\n",
    "        outputdistr_gmm.append(gmm)\n",
    "        outputdistr_stats.iloc[i, :] = [N, logprob]\n",
    "    return outputdistr_gmm, outputdistr_stats\n",
    "\n",
    "class2label = [0, 101, 102, 103, 104, 105]\n",
    "outputdistr_gmm, outputdistr_stats = make_outputdistr(train_reduced, train_len, train_labels, class2label)\n",
    "outputdistr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loglikelihood(mc, x, prob_mass, gmms):\n",
    "    \"\"\"\n",
    "    Compute log likelihood for each observation sample given the MarkovChain of top-layer hmm, \n",
    "    and gmm distribution P(X(t) | activity label = i).\n",
    "    Input:\n",
    "    mc: MarkovChain for top-layer hmm. \n",
    "    prob_mass: probability mass for output distribution of top-layer hmm. \n",
    "               prob_mass[i, j] = P[activity_label = j | S_{hmm_top} = i]\n",
    "    gmms: list of gmm object. gmms[i] has P(X(t) | activity_label = i)\n",
    "    Return:\n",
    "    logp_x: [n_states, n_samples]. logp_x[i, t] = log P[X(t) | S_{hmm_top} = i]\n",
    "    Method:\n",
    "    Compute: P(X(t) | state = i ) for t = 0...T, i = 0...5,\n",
    "    P(X(t) | state = i ) = \\sum_{label i} P(X(t) | label = j, state = i) * P(label = j | state = i)\n",
    "    \"\"\"\n",
    "    T = x.shape[0]\n",
    "    n_states = mc.n_states\n",
    "    logp_x = np.zeros((n_states, T))\n",
    "    for state in range(0, mc.n_states):\n",
    "        label_ind = np.argwhere(prob_mass[state, :] > 0)\n",
    "        p0 = prob_mass[state, prob_mass[state, :] > 0]\n",
    "        logprob_per_label = gmms[0].logprob(x, [gmms[i] for i in label_ind])\n",
    "        logp_x[state, :] = np.log( p0[np.newaxis, :].dot(np.exp(logprob_per_label)) )[0, :]\n",
    "\n",
    "    return logp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi_state_sequence(mc, x, x_len, prob_mass, gmms):\n",
    "    \"\"\"\n",
    "    Predict top-layer hmm state sequence using viterbi algorithm.\n",
    "    Input\n",
    "    x: [T, data_size]. vector sequence stacked together\n",
    "    x_len: length of subsequences\n",
    "    mc:        MarkovChain for top-layer hmm.\n",
    "    prob_mass: probability mass for output distribution of top-layer hmm. \n",
    "               prob_mass[i, j] = P[activity_label = j | S_{hmm_top} = i]\n",
    "    gmms:      list of gmm object. gmms[i] has P(X(t) | activity_label = i)\n",
    "    Return:\n",
    "    s_opt: [T, ] predicted top-layer hmm state sequence\n",
    "    logP: [n_seq, ] logP of each subsequence\n",
    "    \"\"\"\n",
    "    start_ind = 0\n",
    "    s_opt = np.zeros((x.shape[0]))\n",
    "    logP = np.zeros((len(x_len)))\n",
    "    for i in range(0, len(x_len)):\n",
    "        logp_x = loglikelihood(mc, x[start_ind:start_ind + x_len[i], :], prob_mass, gmms)\n",
    "        s_opt[start_ind: start_ind + x_len[i]], logP[i] = mc.viterbi(logp_x)\n",
    "        start_ind += x_len[i]\n",
    "    return s_opt - 1, logP # the state sequence index from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict label within each state\n",
    "# Make an ergordic hmm with output distribution 1.0, (1-to-1 mapping between label and substate)\n",
    "\n",
    "train_states, _ = hmm_state.viterbi(label_transfer)\n",
    "train_states -= 1\n",
    "# train_states, _ = viterbi_state_sequence(hmm_state.state_gen, train_reduced, train_len, prob_mass, outputdistr_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sub_hmm(train_states, train_len, train_labels, n_states):\n",
    "    \"\"\"\n",
    "    Initialize and train the sub-layer hmm for each top-layer hmm state.\n",
    "    For the sub-layer hmm, each state corresponds to one activity label. \n",
    "    We train the transition prob by running Baum-Weltch EM training, by initializing the output \n",
    "    probability mass as the diagonal matrix, to force one to one mapping between sub-layer state and label.\n",
    "    Input:\n",
    "    train_states: [n_samples, ]. Sequence of top-layer hmm states.\n",
    "    train_len: list. Length of subsequences.\n",
    "    train_labels: [n_samples, ]. Activity labels of training sequence. The range of each label must be in [0, n_states)\n",
    "    Return:\n",
    "    mc_per_state: list of MarkovChain objects. mc_per_state[i] is the MarkovChain for top-layer state i. \n",
    "    \"\"\"\n",
    "    train_labels = train_labels[:, np.newaxis]\n",
    "    start_ind = [0] + list(np.cumsum(train_len)[:-1].astype(int))\n",
    "    mc_per_state = []\n",
    "    for n in range(0, n_states):\n",
    "        x_labels = train_labels[train_states == n, :]\n",
    "        x_len = np.array([np.sum(train_states[s:s + train_len[i]] == n) for i, s in enumerate(start_ind)])\n",
    "        x_len = x_len[x_len > 0]\n",
    "        # Aii = 1 - 1/state_duration, Aij = 1/state_duration / (n_states_actual - 1)\n",
    "        A0 = np.eye((n_states))\n",
    "        D = np.array([np.sum(x_labels == i) / float(len(x_len)) for i in range(0, n_states)])\n",
    "        n_states_actual = np.sum(D > 0)\n",
    "        for i in range(0, n_states):\n",
    "            if D[i] == 0:\n",
    "                continue\n",
    "            A0[i, D > 0] = 1.0 / D[i] / n_states_actual\n",
    "            A0[i, i] = 1.0 - 1.0 / D[i]\n",
    "        p0 = np.ones((n_states)) / float(n_states_actual)\n",
    "        p0[D == 0] = 0.0\n",
    "        prob_mass = np.eye((n_states))\n",
    "        pD = [DiscreteDistr(prob_mass[i, :]) for i in range(0, n_states)]\n",
    "        mc = MarkovChain(p0, A0)\n",
    "        hmm_mc = HMM(mc, pD)\n",
    "        hmm_mc.train(obs_data=x_labels + 1, l_data=x_len) # discrete distribution index from 1 \n",
    "        mc_per_state.append(hmm_mc.state_gen)\n",
    "        \n",
    "    return mc_per_state\n",
    "    \n",
    "sub_mcs = make_sub_hmm(train_states, train_len, np.maximum(0, train_labels - 100), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict activity labels inside each high-level hmm state\n",
    "def predict_subhmm_labels(level_one_states, obs_data, l_data, sub_mcs, outputdistr):\n",
    "    # Input:\n",
    "    # level_one_states: [n_samples, ]. Sequences of states of high level hmm.\n",
    "    # obs_data: [n_samples, n_features]\n",
    "    # l_data: length of sequences. sum(l_data) = len(level_one_states)\n",
    "    # sub_mcs: MarkovChain objects for each high-level state. The order of states in the mc corresponds to the low-level label.\n",
    "    # outputdistr: the output distribution for the states in sub_mcs.\n",
    "    # Return:\n",
    "    # labels_opt: [n_samples, ]. predicted labels\n",
    "    start_ind = [0] + list(np.cumsum(l_data)[:-1].astype(int))\n",
    "    labels_opt = np.zeros((level_one_states.shape[0]))\n",
    "    cur_pos = 0\n",
    "    for t in range(0, len(l_data)):\n",
    "        state_subseq = level_one_states[start_ind[t]:start_ind[t] + l_data[t]]\n",
    "        obs_subseq = obs_data[start_ind[t]:start_ind[t] + l_data[t], :]\n",
    "        diff = np.append(np.array([1]), state_subseq[1:] - state_subseq[:-1])\n",
    "        i_newstate = np.append( np.argwhere(diff != 0), np.array([len(diff)]) )\n",
    "        for m in range(0, len(i_newstate) - 1):\n",
    "            state_tt = int(state_subseq[i_newstate[m]])\n",
    "            obs_tt = obs_subseq[i_newstate[m]:i_newstate[m + 1], :]\n",
    "            # run viterbi on markov chain sub_mcs[state_tt]\n",
    "            logp_x = outputdistr[0].logprob(obs_tt, outputdistr)\n",
    "            labels_tt, logP = sub_mcs[state_tt].viterbi(logp_x)\n",
    "            labels_opt[cur_pos:cur_pos + len(labels_tt)] = labels_tt - 1 # make the label index starting from 0\n",
    "            cur_pos += len(labels_tt)\n",
    "    return labels_opt   \n",
    "\n",
    "# Predict test labels\n",
    "test_states, _ = viterbi_state_sequence(hmm_state.state_gen, test_reduced, test_len, prob_mass, outputdistr_gmm)\n",
    "predicted_labels = predict_subhmm_labels(test_states, test_reduced, test_len, sub_mcs, outputdistr_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAEZCAYAAACZ7CwhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOU5kM1oIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109e7f450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.800242681632\n"
     ]
    }
   ],
   "source": [
    "# Test with ADL4, ADL5\n",
    "true_labels = np.maximum(0, test_labels - 100)\n",
    "\n",
    "plt.plot(predicted_labels, '.', label=\"estimated label\")\n",
    "plt.plot(true_labels, '-', label=\"true label\")\n",
    "plt.plot(test_states, '--', label=\"high-level states\")\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('Activity label')\n",
    "plt.title(\"ADL4, ADL5 -- person %d\" % person)\n",
    "plt.legend(loc=9, bbox_to_anchor=(1.2, 1))\n",
    "plt.show()\n",
    "\n",
    "print \"accuracy: \", sum(predicted_labels == true_labels) / float(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score:  0.805945762705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8995943</td>\n",
       "      <td>0.5346594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8498498</td>\n",
       "      <td>0.876161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4260753</td>\n",
       "      <td>0.9215116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9545085</td>\n",
       "      <td>0.9407526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8382732</td>\n",
       "      <td>0.999232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9930209</td>\n",
       "      <td>0.7259475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision     recall\n",
       "0  0.8995943  0.5346594\n",
       "1  0.8498498   0.876161\n",
       "2  0.4260753  0.9215116\n",
       "3  0.9545085  0.9407526\n",
       "4  0.8382732   0.999232\n",
       "5  0.9930209  0.7259475"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print \"Weighted F1 score: \", f1_score(true_labels, predicted_labels, average='weighted') \n",
    "\n",
    "precision, recall , _, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=None, labels=[0, 1, 2, 3, 4, 5])\n",
    "pr_table = pd.DataFrame(index=range(0, 6), columns=['precision', 'recall'])\n",
    "for i in range(0, n_states):\n",
    "    pr_table.iloc[i, :] = [precision[i], recall[i]]\n",
    "pr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
